# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tEY8LHeWkRiZE5yQMqYii4H6tkzAukL1
"""

from langchain import LLMChain
from langchain.prompts import PromptTemplate
from langchain.llms import HuggingFaceHub
from langchain.document_loaders import WebBaseLoader
from langchain.text_splitter import CharacterTextSplitter

# 네이버 뉴스기사 주소
# url = 'https://n.news.naver.com/article/437/0000361628?cds=news_media_pc'

# 웹 문서 크롤링
loader = WebBaseLoader(url)

# 뉴스기사의 본문을 Chunk 단위로 쪼갬
text_splitter = CharacterTextSplitter(
    separator="\n\n",
    chunk_size=3000,     # 쪼개는 글자수
    chunk_overlap=300,   # 오버랩 글자수
    length_function=len,
    is_separator_regex=False,
)

# 웹사이트 내용 크롤링 후 Chunk 단위로 분할
docs = loader.load_and_split(text_splitter)

# 각 Chunk 단위의 템플릿
template = '''다음의 내용을 한글로 요약해줘:

{text}
'''

# 전체 문서(혹은 전체 Chunk)에 대한 지시(instruct) 정의
combine_template = '''{text}

요약의 결과는 다음의 형식으로 작성해줘:
제목: 신문기사의 제목
주요내용: 한 줄로 요약된 내용
작성자: 김철수 대리
내용: 주요내용을 불렛포인트 형식으로 작성
'''

# 템플릿 생성
prompt = PromptTemplate(template=template, input_variables=['text'])
combine_prompt = PromptTemplate(template=combine_template, input_variables=['text'])

# HuggingFaceHub 객체 생성
huggingface_model_repo = 'beomi/llama-2-ko-7b'  # Hugging Face 모델의 ID 또는 Repository 이름
llm = HuggingFaceHub(
    repo_id=huggingface_model_repo,
    model_kwargs={"temperature": 0.2, "max_length": 128, "timeout": 120}  # 모델 인자
)

# LLM Chain 객체 생성
llm_chain = LLMChain(prompt=combine_prompt, llm=llm)  # combine_prompt를 사용합니다.

# 문서를 문자열로 결합
full_text = "\n\n".join([chunk.content for chunk in docs if hasattr(chunk, 'content')])

# 요약 생성
summary = llm_chain.run(text=full_text)  # 'text' 변수에 대한 키워드 인자를 사용합니다.

# 결과 출력
print(summary)